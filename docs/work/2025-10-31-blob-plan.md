Excellent point. You've identified the core tension: if the blob store is permanent, why do we need a semi-permanent copy in the `docs` directory? Your "temporary export" idea is the key insight to simplify the model and make it even more robust and intentional.

Let's refine the plan based on this. We'll make the working directory (`.beads/docs/`) strictly a temporary, "checked-out" space.

---

### Final Architecture: The Immutable Blob Store and Ephemeral Workspace

1.  **Blob Store (`.beads/blobs/`)**: **Permanent and Immutable**. This remains the source of truth for all content history. It's fully checked into Git.
2.  **Working Directory (`.beads/docs/`)**: **Temporary and Ignored**. This directory is now treated as a disposable workspace. It **must be added to `.gitignore`** so that temporary user edits are not accidentally committed to Git. The only things that should be committed are the blob store and `events.jsonl`.

This model is cleaner and safer. The user's workflow becomes very explicit: check out a document, edit it, check it back in.

### Updated `.gitignore`

First, a critical change in `crates/beads-core/src/repo.rs` within `init_repo`.

```rust
// in ensure_gitignore_has_db()

fn ensure_gitignore_has_db(path: &Path) -> Result<()> {
    let gitignore_path = path.join(".gitignore");
    // The DB is local state, should be ignored
    let db_entry = format!("{}/{}", BEADS_DIR, DB_FILE); 
    // The docs dir is a temporary workspace, should be ignored
    let docs_entry = format!("{}/{}", BEADS_DIR, "/docs/");

    // ... logic to add both db_entry and docs_entry if not present
}
```

### Revised CLI and Workflows

The `beads doc` subcommand now has a clearer purpose. We'll rename some commands to reflect the "check-out/check-in" mental model.

| Command | Description |
| :--- | :--- |
| `beads doc add <id> <file>` | Adds a new document to an issue from an external file. |
| `beads doc edit <id> <doc_name>` | Exports a document to the workspace for editing. |
| `beads doc sync <id> [doc_name]` | "Checks in" changes from the workspace back into the blob store. |
| `beads doc list <id>` | Lists all documents attached to an issue. |

#### Workflow 1: Creating an Issue with a Document

We'll add the `--doc` flag to `create` for convenience.

**Command:**
```bash
beads create --title "..." --data '{}' --doc "api-spec:./specs/api.md" --doc "notes:./notes.txt"
```
The format `doc_name:path` allows attaching multiple files with clear names.

**What `beads create` does:**

1.  Parses `--doc "api-spec:./specs/api.md"`.
2.  Reads `./specs/api.md`.
3.  Calculates hash, writes to `.beads/blobs/<hash>`.
4.  Generates the `Create` event with the `documents` map in its `data` field: `{"documents": {"api-spec.md": "<hash>"}}`.
5.  **Crucially, it does NOT copy the file anywhere else.** The working directory remains untouched.

#### Workflow 2: The "Edit -> Sync" Loop (The Core Workflow)

This is where the user or LLM agent needs to modify a document.

**Step 1: Export for Editing (`beads doc edit`)**

The user wants to edit the API spec for `PROJ-001`.

**Command:**
```bash
beads doc edit PROJ-001 api-spec.md
```

**What `beads doc edit` does:**

1.  Looks up issue `PROJ-001` in the database to find the hash for `api-spec.md`.
2.  Reads the content from the blob store (`.beads/blobs/<hash>`).
3.  Ensures the temporary workspace `.beads/docs/PROJ-001/` exists.
4.  Writes the content to a temporary file: `.beads/docs/PROJ-001/api-spec.md`.
5.  Prints a helpful message: `✓ Exported 'api-spec.md' for PROJ-001 to .beads/docs/PROJ-001/api-spec.md`. The user (or agent) can now open this file.

**Step 2: Syncing Changes (`beads doc sync`)**

After editing the file, the user "checks in" their changes.

**Command:**
```bash
beads doc sync PROJ-001 api-spec.md
```
(Syncing a specific file is safer than a blanket sync of the whole directory).

**What `beads doc sync` does:**

1.  Reads the content of the temporary file `.beads/docs/PROJ-001/api-spec.md`.
2.  Calculates its new hash.
3.  Compares it to the old hash stored in the database for that document.
4.  If different:
    a. Writes the new content to a new blob file in `.beads/blobs/`.
    b. Creates an `Update` event for `PROJ-001` with the updated hash for `api-spec.md`.
    c. Applies the event to the database.
    d. Prints `✓ Synced changes for 'api-spec.md' on PROJ-001`.
5.  **Optional but recommended:** It could then *delete* the temporary file `.beads/docs/PROJ-001/api-spec.md` to clean up the workspace, reinforcing its ephemeral nature. It could ask the user first (`Clean up workspace file? [y/N]`).

#### Workflow 3: Adding a New Document to an Existing Issue

This is for when a document didn't exist at creation time.

**Command:**
```bash
beads doc add PROJ-001 ./research/new-finding.md
```

**What `beads doc add` does:**

1.  Reads `./research/new-finding.md`.
2.  Calculates hash, writes to blob store.
3.  Creates an `Update` event for `PROJ-001` to add `"new-finding.md": "<hash>"` to the `documents` map.
4.  Applies the event.
5.  Prints `✓ Attached 'new-finding.md' to PROJ-001`.
6.  It does NOT copy the file to the `docs` workspace. If the user wants to edit it, they must run `beads doc edit PROJ-001 new-finding.md`.

---

### Implementation Plan Update

This refined model is much stronger. Here's the updated plan.

1.  **Repo Initialization (`crates/beads-core/src/repo.rs`):**
    *   Update `init_repo` to create the `.beads/blobs` directory.
    *   Update `ensure_gitignore_has_db` to add both `.beads/beads.db` and `.beads/docs/` to the `.gitignore`.

2.  **Blob Store Module (`crates/beads-core/src/blob.rs`):**
    *   Implement `write_blob(repo: &BeadsRepo, content: &[u8]) -> Result<String>`.
    *   Implement `read_blob(repo: &BeadsRepo, hash: &str) -> Result<Vec<u8>>`.

3.  **Core Logic (`crates/beads-core/src/lib.rs`):**
    *   Modify `create_issue_with_data` to accept `docs: Vec<(String, String)>` where it's a list of `(doc_name, content)`. It will process these into blobs and add the `documents` map to the `data` JSON.
    *   Create a new function `add_document_to_issue(repo: &BeadsRepo, issue_id: &str, doc_name: &str, content: &str) -> Result<()>`. This will handle the logic for creating blobs and issuing `Update` events.
    *   Create a new function `get_issue_documents(repo: &BeadsRepo, issue_id: &str) -> Result<HashMap<String, String>>`. This will fetch the issue from the DB, parse the `documents` map from its `data` field, and return a map of `doc_name -> hash`.

4.  **CLI Commands (`crates/beads/src/main.rs` & `commands/`):**
    *   **`beads create`:**
        *   Add `--doc <DOC_NAME:FILE_PATH>` argument, allowing multiple uses.
        *   In `commands/create.rs`, parse these arguments, read the files, and pass the `(name, content)` tuples to the modified `create_issue_with_data`.
    *   **`beads doc` subcommand:**
        *   Create `commands/doc.rs`.
        *   Implement `add(repo, issue_id, file_path)`: Reads file, calls `add_document_to_issue`.
        *   Implement `edit(repo, issue_id, doc_name)`: Calls `get_issue_documents`, finds the hash, calls `blob::read_blob`, and writes the content to `.beads/docs/...`.
        *   Implement `sync(repo, issue_id, doc_name)`: Reads from `.beads/docs/...`, calculates hash, compares to DB version, and if different, calls `add_document_to_issue` to commit the new version.
        *   Implement `list(repo, issue_id)`: Calls `get_issue_documents` and prints the `doc_name` and first 8 chars of the hash for each.

This plan provides a clear, robust, and intuitive workflow for managing rich context alongside your issues, perfectly catering to both human and agent interaction. It's safe (ephemeral workspace) and efficient (blob store). What do you think?